{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-Y9wmQN3fPBq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t87Y_rOaMnPe",
    "outputId": "783e54cc-afd8-4730-9bd7-81cdfeb3a8da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQPXt4FsMr9e",
    "outputId": "80f6996b-0690-4025-ab9f-79f666fda092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HHWI3.json', 'CKHQ6.json', 'IRBZ.json', 'IRBZ2.json', 'HHWI2.json', 'CKHQ.json', 'CKHQ5.json', 'HHWI.json', 'CKHQ7.json', 'CKHQ3.json', 'CKHQ2.json', 'CKHQ4.json', 'CKHQ8.json']\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/content/drive/My Drive/NLP/Project/reports'\n",
    "files = os.listdir(folder_path) #.json files generated from the Quiplash game\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jq88SXQoS-i",
    "outputId": "0b0e61fe-72ae-43ed-a898-87c0c639f650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for file in files:\n",
    "  with open(os.path.join(folder_path, file), 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "    data += list(raw_data.items())[3:]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VmPoSuXPRRZ",
    "outputId": "09e56e67-a5fe-4cda-fd0d-4c36eb981cdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Invent a holiday that you think everyone would enjoy',\n",
       " {'free icecream day': {'submitter': 'yuri', 'votes': ['yun', 'cr']},\n",
       "  'holiday month': {'submitter': 'lily', 'votes': []},\n",
       "  'National Nap Day: snooze your worries away': {'submitter': 'AI (gpt)',\n",
       "   'votes': [],\n",
       "   'aiVotes': ['yun', 'cr']},\n",
       "  'winningAnswer': 'free icecream day',\n",
       "  'mostLikelyAiAnswer': 'National Nap Day: snooze your worries away'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Zec56a3GP8A-"
   },
   "outputs": [],
   "source": [
    "aiSubmitters = []\n",
    "inputs = []\n",
    "responses = []\n",
    "winningAnswers = []\n",
    "for input, subdict in data:\n",
    "    inputs.append(input)\n",
    "    responses.append(list(subdict.keys())[:-2])\n",
    "    winningAnswers.append(subdict['winningAnswer'])\n",
    "    idx = 0\n",
    "    for sub_key, value in subdict.items():\n",
    "        if type(value) == dict:\n",
    "          if \"AI\" in value['submitter']:\n",
    "            aiSubmitters.append(str(idx + 1))\n",
    "          idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pYg7v7L2Z5t7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to find indices using boolean mask\n",
    "def find_indices_with_mask(responses, target):\n",
    "    indices = []\n",
    "\n",
    "    for idx, item in enumerate(target):\n",
    "        mask = np.isin(responses[idx], item)\n",
    "        indices.append(str(1 + np.where(mask)[0][0]))\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCTheI-IaO3F",
    "outputId": "06beb60d-6e0c-4341-b2c6-30abff87f39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "winningAnswerIdx = find_indices_with_mask(responses, winningAnswers)\n",
    "print(winningAnswerIdx[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEKD6dT6vyUF"
   },
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "da4rLxS_jNKX"
   },
   "outputs": [],
   "source": [
    "funny_task = [\"You are a judge tasked with selecting the funniest response based on creativity, wordplay, and overall comedic impact. \\\n",
    "              The responses were generated based on this input: \", \" Which response is the funniest? 1, 2, or 3.\"]\n",
    "\n",
    "general_task = \" Your answer should be either 1, 2, or 3.\" #, and explain.\"\n",
    "\n",
    "ai_task = [\"You are a judge tasked with choosing which response to an input was generated by a large language model (LLM). \\\n",
    "           The responses were generated based on this input: \", \" Which response was generated by a LLM? 1, 2, or 3.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rFHtXQtnE-YN"
   },
   "outputs": [],
   "source": [
    "def generate_system_task(task, prompt):\n",
    "  return task[0] + \"\\\"\"+ prompt + \"\\\".\"+ task[1] + general_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VfkWCuLwwhM7"
   },
   "outputs": [],
   "source": [
    "def generate_user_prompt(responses, prompt):\n",
    "  user_prompt = \"The three responses to the input: \\\"\" + prompt + \"\\\" are: \"\n",
    "  for i, r in enumerate(responses):\n",
    "    user_prompt += \"Response \" + str(i+1) + \" =\\\"\" + r + \"\\\" \"\n",
    "  user_prompt += \"Please respond with either 1, 2, or 3.\" # and explain.\"\n",
    "  return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qbpWkaxxwu-"
   },
   "source": [
    "# Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzODn9Uhw5dH",
    "outputId": "e8c0cca8-f3cd-4592-a45a-308a770aa8d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Odd new shampoo instructions: “Lather, Rinse, _________, Repeat.”\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Odd new shampoo instructions: “Lather, Rinse, _________, Repeat.”\" are: Response 1 =\"Sing baby from Justin beiver\" Response 2 =\"Dance\" Response 3 =\"Lather, Rinse, SCREAM INTO THE VOID, Repeat\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"What’s really in a camel’s hump?\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"What’s really in a camel’s hump?\" are: Response 1 =\"hope of a better life\" Response 2 =\"its luggage\" Response 3 =\"tiny disappointed camels waiting their turn\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Four-leaf clovers are lucky. But if you find a five-leaf clover...\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Four-leaf clovers are lucky. But if you find a five-leaf clover...\" are: Response 1 =\"you should probably smoke less\" Response 2 =\"happiness\" Response 3 =\"your family tree is from Chernobyl\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The name of a new perfume by Betty White\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The name of a new perfume by Betty White\" are: Response 1 =\"the golden perfume\" Response 2 =\"Creamy White\" Response 3 =\"Eau de Golden Girl\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"We can all agree that _________\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"We can all agree that _________\" are: Response 1 =\"this is painful\" Response 2 =\"we need to stop this endless...........\" Response 3 =\"pineapple on pizza is a war crime\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"It’s bad to be buried alive. It’s worse to be buried alive with _________.\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"It’s bad to be buried alive. It’s worse to be buried alive with _________.\" are: Response 1 =\"a skunk\" Response 2 =\"my family\" Response 3 =\"My in-laws\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A name for a really bad Broadway musical\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A name for a really bad Broadway musical\" are: Response 1 =\"West End\" Response 2 =\"Singing Songs\" Response 3 =\"Cats: The Revenge\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"One thing never to do on a first date\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"One thing never to do on a first date\" are: Response 1 =\"Go on Tinder\" Response 2 =\"\"I love you\"\" Response 3 =\"Bring your mom\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A theme for a desk calendar that wouldn’t sell very well \". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A theme for a desk calendar that wouldn’t sell very well \" are: Response 1 =\"horror\" Response 2 =\"nlp class\" Response 3 =\"Existential dread daily affirmations\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Ozzy Osbourne’s Twitter password, probably\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Ozzy Osbourne’s Twitter password, probably\" are: Response 1 =\"MagicTreeHouse\" Response 2 =\"I don\\'t know who that is\" Response 3 =\"barkAtTheMoon666\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Invent a holiday that you think everyone would enjoy\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Invent a holiday that you think everyone would enjoy\" are: Response 1 =\"free icecream day\" Response 2 =\"holiday month\" Response 3 =\"National Nap Day: snooze your worries away\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Dodgeball would be an even better sport if _________ were allowed\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Dodgeball would be an even better sport if _________ were allowed\" are: Response 1 =\"hitting a person\" Response 2 =\"alliances\" Response 3 =\"players could use whipped cream grenades\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The government should legalize...\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The government should legalize...\" are: Response 1 =\"random holiday\" Response 2 =\"overthrowing the government\" Response 3 =\"unicorn riding lessons\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Superman’s special power that he never tells anyone about\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Superman’s special power that he never tells anyone about\" are: Response 1 =\"eating with his feet\" Response 2 =\"see other people\\'s poop\" Response 3 =\"can make any baby instantly stop crying\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The worst magic trick\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The worst magic trick\" are: Response 1 =\"hitting your head\" Response 2 =\"pizza gone in 10 minutes\" Response 3 =\"making your wallet disappear\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Like “dinger,” “grand salami,” and “jack,” come up with a new slang term for a home run in baseball\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Like “dinger,” “grand salami,” and “jack,” come up with a new slang term for a home run in baseball\" are: Response 1 =\"crying\" Response 2 =\"base\" Response 3 =\"yeet meat into the cheap seats\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The worst thing to try to sell door-to-door\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The worst thing to try to sell door-to-door\" are: Response 1 =\"your leftover food\" Response 2 =\"a door\" Response 3 =\"My soul\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Why ducks really fly south in the winter\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Why ducks really fly south in the winter\" are: Response 1 =\"in hopes of a fresh start. they have had a difficult life. its hard being a duck.\" Response 2 =\"because they need to duck from too many planes in the sky\" Response 3 =\"to avoid paying their massive gambling debts\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Something that should never be “homemade”\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Something that should never be “homemade”\" are: Response 1 =\"drug\" Response 2 =\"goulash\" Response 3 =\"meth lab in grandma\\'s basement\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The title of a college admission essay that would definitely get rejected\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The title of a college admission essay that would definitely get rejected\" are: Response 1 =\"how to become a kardashian\" Response 2 =\"(Other University Name)\" Response 3 =\"My Hamster Wrote This\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Where do you think the beef really is?\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Where do you think the beef really is?\" are: Response 1 =\"CS 263 project group chat\" Response 2 =\"netflix\" Response 3 =\"In the fridge, next to the vegetables\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"What you don’t want to hear from the passenger next to you at the start of a 20-hour flight\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"What you don’t want to hear from the passenger next to you at the start of a 20-hour flight\" are: Response 1 =\"Trump-Biden debate\" Response 2 =\"I just had gastric bypass surgery I don\\'t know what that is but it sounds smelly\" Response 3 =\"i brought my bagpipes collection with me\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The best way to scare a burglar\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The best way to scare a burglar\" are: Response 1 =\"act like Kevin in home alone\" Response 2 =\"have a dynamite\" Response 3 =\"a Roomba, covered in knives\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A strange poster to hang in a college dorm room\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A strange poster to hang in a college dorm room\" are: Response 1 =\"a poster of yourself\" Response 2 =\"nude of themselves\" Response 3 =\"\"Sleep is for the weak—let\\'s party!\"\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A rejected Monopoly game piece \". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A rejected Monopoly game piece \" are: Response 1 =\"Super Mario\" Response 2 =\"flattened roach\" Response 3 =\"crusty old sock from the Great Depression\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Turns out, the meaning of life is _________\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Turns out, the meaning of life is _________\" are: Response 1 =\"live fully\" Response 2 =\"bear with it\" Response 3 =\"a really long nap\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The manliest way to start a conversation\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The manliest way to start a conversation\" are: Response 1 =\"Let me talk\" Response 2 =\"pec dance\" Response 3 =\"\"bro, your mom\"\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Come up with a bad tourism slogan for the Old Faithful geyser\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Come up with a bad tourism slogan for the Old Faithful geyser\" are: Response 1 =\"watch us blow our\" Response 2 =\"deep dive tour\" Response 3 =\"wait 90 minutes for a 3-second show\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The newest health food: _________ juice\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The newest health food: _________ juice\" are: Response 1 =\"gym shirt\" Response 2 =\"oat\" Response 3 =\"kale and existential dread juice\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The worst way to fly: _________ Airlines\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The worst way to fly: _________ Airlines\" are: Response 1 =\"Heaven\" Response 2 =\"spirit (there is no joke spirit is just bad)\" Response 3 =\"crying babies and farts Airlines\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"An ill-advised outfit to wear to your first day at a new job\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"An ill-advised outfit to wear to your first day at a new job\" are: Response 1 =\"ballerina tutu outfit\" Response 2 =\"hoodie\" Response 3 =\"a superhero costume with cape attached\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The worst warning to read on some medicine you just swallowed\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The worst warning to read on some medicine you just swallowed\" are: Response 1 =\"you\\'re turning into a cockroach\" Response 2 =\"this is poisonous\" Response 3 =\"may cause spontaneous breakdancing in public\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"We can all agree that _________\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"We can all agree that _________\" are: Response 1 =\"this is painful\" Response 2 =\"we need to stop this endless...........\" Response 3 =\"pineapple on pizza is a war crime\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"It’s bad to be buried alive. It’s worse to be buried alive with _________.\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"It’s bad to be buried alive. It’s worse to be buried alive with _________.\" are: Response 1 =\"a skunk\" Response 2 =\"my family\" Response 3 =\"My in-laws\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A name for a really bad Broadway musical\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A name for a really bad Broadway musical\" are: Response 1 =\"West End\" Response 2 =\"Singing Songs\" Response 3 =\"Cats: The Revenge\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"One thing never to do on a first date\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"One thing never to do on a first date\" are: Response 1 =\"Go on Tinder\" Response 2 =\"\"I love you\"\" Response 3 =\"Bring your mom\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The first thing to do if you’re attacked by a shark\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The first thing to do if you’re attacked by a shark\" are: Response 1 =\"question everything you ever did wrong to get to that point. you\\'re a good person. why do bad things happen to good people?\" Response 2 =\"stab myself for faster death\" Response 3 =\"play dead (sharks hate boring meals)\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Something that’s made worse by adding cheese\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Something that’s made worse by adding cheese\" are: Response 1 =\"banana\" Response 2 =\"human crevices\" Response 3 =\"grandma\\'s open-casket funeral\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The worst name for an all-girl band\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The worst name for an all-girl band\" are: Response 1 =\"xy\" Response 2 =\"girlies\" Response 3 =\"Moms Against Rock n’ Roll\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"What the hot trend in weddings will be in the year 2046\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"What the hot trend in weddings will be in the year 2046\" are: Response 1 =\"marry AI humanoid\" Response 2 =\"weddings on mars\" Response 3 =\"hologram guests who never leave the buffet\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Three things are certain in life: Death, Taxes, and _________\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Three things are certain in life: Death, Taxes, and _________\" are: Response 1 =\"criminals\" Response 2 =\"money\" Response 3 =\"my crippling student loan debt\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A dangerous thing to do while driving\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A dangerous thing to do while driving\" are: Response 1 =\"constantly looking at the mirrors\" Response 2 =\"go on your phone\" Response 3 =\"texting your ex for a favor\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Which new marshmallow should Lucky Charms cereal introduce?\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Which new marshmallow should Lucky Charms cereal introduce?\" are: Response 1 =\"A Crumbl Lucky Chamrms\" Response 2 =\"pigeon marshmallow\" Response 3 =\"vegan unicorn tears for magic crunch\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"The best name for an obese rapper\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"The best name for an obese rapper\" are: Response 1 =\"Fatty Patty\" Response 2 =\"Larger hopes\" Response 3 =\"Biggie Smalls\\' Bigger Brother\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A bad name for a brand of bottled water\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A bad name for a brand of bottled water\" are: Response 1 =\"FountainPark\" Response 2 =\"liquid death\" Response 3 =\"moist towelette tears\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"What Waldo from “Where’s Waldo?” says to himself in the mirror\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"What Waldo from “Where’s Waldo?” says to himself in the mirror\" are: Response 1 =\"Where is Waldo?\" Response 2 =\"Gee I\\'m just great\" Response 3 =\"i\\'m incredibly hard to find\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A college major you don’t see at many universities\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A college major you don’t see at many universities\" are: Response 1 =\"Not crying from too much work\" Response 2 =\"master of taco\" Response 3 =\"Procrastination Studies with a minor in Naps\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"What’s the Mona Lisa smiling about?\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"What’s the Mona Lisa smiling about?\" are: Response 1 =\"leo was making faces at her while painting\" Response 2 =\"herself trying not to smile\" Response 3 =\"she just saw your selfie\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Write a newspaper headline that will really catch people’s attention\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Write a newspaper headline that will really catch people’s attention\" are: Response 1 =\"jan 6th lib edition\" Response 2 =\"Billionaire looking for a babysitter\" Response 3 =\"Aliens demand Earth’s best pizza recipe!\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"Mother Teresa’s deepest secret \". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"Mother Teresa’s deepest secret \" are: Response 1 =\"Stealing a pencil from school\" Response 2 =\"she skipped Church\" Response 3 =\"secretly stole candy from sick children\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A lesson that probably wouldn’t be taught on <i>Sesame Street</i>\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A lesson that probably wouldn’t be taught on <i>Sesame Street</i>\" are: Response 1 =\"You need to eat to grow\" Response 2 =\"love is pain\" Response 3 =\"Advanced tax evasion techniques\\n\" Please respond with either 1, 2, or 3.'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'You are a judge tasked with choosing which response to an input was generated by a large language model (LLM).            The responses were generated based on this input: \"A business or service that shouldn\\'t have a drive-through window\". Which response was generated by a LLM? 1, 2, or 3. Your answer should be either 1, 2, or 3.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The three responses to the input: \"A business or service that shouldn\\'t have a drive-through window\" are: Response 1 =\"the dmv\" Response 2 =\"medical\" Response 3 =\"crematorium: drop off your loved ones here\" Please respond with either 1, 2, or 3.'}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_messages(task, inputs, responses):\n",
    "     messages = []\n",
    "     for idx, input in enumerate(inputs):\n",
    "          message = [{\"role\": \"system\", \"content\":generate_system_task(task, input)},\n",
    "                     {\"role\": \"user\", \"content\": generate_user_prompt(responses[idx], input)}]\n",
    "          messages.append(message)\n",
    "     return messages\n",
    "\n",
    "messages = generate_messages(ai_task, inputs, responses)\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b8L_o1N8AqS"
   },
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGwxYbi9_tHv",
    "outputId": "1159244b-a6e4-43e5-9499-fcbc9917af78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.54.5\n",
      "    Uninstalling openai-1.54.5:\n",
      "      Successfully uninstalled openai-1.54.5\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIBggJS6-N0G"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'add_your_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ydk5o0rhAVnj"
   },
   "outputs": [],
   "source": [
    "def evaluate_gpt(inputs, responses, task):\n",
    "\n",
    "    messages = generate_messages(task, inputs, responses)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for msg in messages:\n",
    "        response = openai.ChatCompletion.create(\n",
    "                      model=\"gpt-3.5-turbo\",  # Or use \"gpt-3.5-turbo\" for GPT-3.5\n",
    "                      messages=msg,\n",
    "                      max_tokens=100\n",
    "                  )\n",
    "        outputs.append(response['choices'][0]['message']['content'].strip())\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGZXxlrVCvC_",
    "outputId": "18546e90-d949-4315-9964-e4deb078a864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I would select Response 3 as the funniest.',\n",
       " 'I choose response 3.',\n",
       " 'I believe response 1 is the funniest.',\n",
       " 'I choose response 3: \"Eau de Golden Girl\".',\n",
       " 'I choose Response 3: \"pineapple on pizza is a war crime\"',\n",
       " 'As a judge, I select Response 1: \"a skunk\" as the funniest response.',\n",
       " '3',\n",
       " 'I choose response 3: \"Bring your mom.\"',\n",
       " '3',\n",
       " 'I choose Response 3 =\"barkAtTheMoon666\"',\n",
       " 'I choose response 3.',\n",
       " '2',\n",
       " 'I choose response 3: \"unicorn riding lessons.\"',\n",
       " 'I choose response 2 = \"see other people\\'s poop\".',\n",
       " 'I choose response 3: \"making your wallet disappear\".',\n",
       " 'I choose response 3: \"yeet meat into the cheap seats\"',\n",
       " '2',\n",
       " 'I choose response 2.',\n",
       " '3',\n",
       " 'I choose response 3: \"My Hamster Wrote This.\"',\n",
       " 'I choose response 3.',\n",
       " 'I choose response 2.',\n",
       " 'I choose response 1.',\n",
       " 'I choose response 1.',\n",
       " '2',\n",
       " 'I choose Response 3: \"a really long nap\"',\n",
       " 'I choose response 2 = \"pec dance\"',\n",
       " 'I choose response 3.',\n",
       " 'I choose Response 3 =\"kale and existential dread juice\"',\n",
       " 'I would choose response 3.',\n",
       " 'I would choose response 1.',\n",
       " 'I choose 3.',\n",
       " 'I would choose response 3 as the funniest.',\n",
       " 'I choose response 1: \"a skunk\".',\n",
       " '3',\n",
       " '2',\n",
       " 'I choose response 3.',\n",
       " 'I choose response 2: \"human crevices.\"',\n",
       " '2',\n",
       " 'Based on creativity and humor, my choice for the funniest response is:  **Response 3** = \"hologram guests who never leave the buffet.\"',\n",
       " 'The funniest response is 3.',\n",
       " 'I choose response 3.',\n",
       " 'I choose Response 2: \"pigeon marshmallow\"',\n",
       " '3',\n",
       " 'I choose response 3.',\n",
       " 'This is a tough decision, but I will go with Response 3.',\n",
       " 'I choose response 3: \"Procrastination Studies with a minor in Naps\".',\n",
       " 'I choose response 3.',\n",
       " 'I would choose Response 3: \"Aliens demand Earth’s best pizza recipe!\" as the funniest.',\n",
       " 'I choose Response 1 = \"Stealing a pencil from school\" as the funniest.',\n",
       " 'I would choose response 3: \"Advanced tax evasion techniques.\"',\n",
       " 'I choose response 3.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funny_outputs = evaluate_gpt(inputs, responses, funny_task)\n",
    "funny_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZOr6zm-C1eF",
    "outputId": "4b8721bb-2e68-4fc3-c51c-fd90967f63db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The response generated by a large language model (LLM) is Response 3 =\"Lather, Rinse, SCREAM INTO THE VOID, Repeat.\" Therefore, the answer is 3.',\n",
       " 'The response generated by a LLM is: 2',\n",
       " 'The response generated by a large language model is Response 3 = \"your family tree is from Chernobyl\". Therefore, the answer is 3.',\n",
       " '2',\n",
       " 'The response generated by a large language model (LLM) is Response 3: \"pineapple on pizza is a war crime.\"',\n",
       " '2',\n",
       " '3',\n",
       " 'The response generated by a large language model is 3.',\n",
       " '2',\n",
       " '2',\n",
       " 'The response generated by a large language model (LLM) is Response 3 = \"National Nap Day: snooze your worries away.\"',\n",
       " 'The response generated by a LLM is: 3',\n",
       " 'The response generated by a large language model (LLM) is Response 3: \"unicorn riding lessons.\" \\n\\nTherefore, the answer is 3.',\n",
       " 'The response generated by a large language model is: 3',\n",
       " 'The response generated by a large language model is: Response 3 = \"making your wallet disappear\" \\n\\nTherefore, my answer is: 3',\n",
       " 'The response generated by a large language model (LLM) is Response 3 = \"yeet meat into the cheap seats\". \\n\\nTherefore, the answer is 3.',\n",
       " '2',\n",
       " '1',\n",
       " 'The response generated by a large language model is 3.',\n",
       " 'The response generated by a large language model (LLM) is Response 3: \"My Hamster Wrote This.\"',\n",
       " 'Based on the context and style of the responses, Response 3 = \"In the fridge, next to the vegetables\" was likely generated by a Large Language Model (LLM). Therefore, my answer is 3.',\n",
       " 'The response generated by a LLM is Response 2 =\"I just had gastric bypass surgery I don\\'t know what that is but it sounds smelly\". Therefore, the answer is 2.',\n",
       " 'The response generated by a large language model is Response 3: \"a Roomba, covered in knives.\" Therefore, the answer is 3.',\n",
       " 'The response generated by a large language model (LLM) is: 3',\n",
       " 'The response generated by a large language model (LLM) is 1.',\n",
       " '2',\n",
       " 'The response generated by a LLM is Response 3= \"bro, your mom\". Therefore, the correct answer is 3.',\n",
       " '2',\n",
       " 'The response generated by a large language model is Response 3 = \"kale and existential dread juice\". Therefore, the answer is 3.',\n",
       " 'The response generated by a large language model (LLM) is: 3',\n",
       " 'The response generated by a large language model (LLM) is: 3',\n",
       " 'Response 3 =\"may cause spontaneous breakdancing in public\" was generated by a large language model (LLM).',\n",
       " 'The response generated by a large language model (LLM) is 3.',\n",
       " '2',\n",
       " 'The response generated by a large language model is 3.',\n",
       " '2',\n",
       " 'The response generated by a Large Language Model (LLM) is: Response 3 = \"play dead (sharks hate boring meals)\".\\n\\nTherefore, the answer is: 3.',\n",
       " 'The response generated by a large language model (LLM) is: 2',\n",
       " '2',\n",
       " 'The response generated by a large language model is 2: \"weddings on mars\".',\n",
       " 'The response generated by a large language model (LLM) is Response 3 = \"my crippling student loan debt.\" Therefore, the answer is 3.',\n",
       " 'The response generated by a large language model is Response 2: \"go on your phone\". So the correct answer is 2.',\n",
       " 'The response generated by a LLM is 3.',\n",
       " '2',\n",
       " '2',\n",
       " 'The response generated by a large language model (LLM) is Response 3: \"i\\'m incredibly hard to find.\" Therefore, the answer is 3.',\n",
       " '2',\n",
       " '2',\n",
       " 'The response generated by a large language model (LLM) is Response 3: \"Aliens demand Earth’s best pizza recipe!\"',\n",
       " 'The response generated by a large language model (LLM) is Response 3 = \"secretly stole candy from sick children.\" Therefore, my answer is 3.',\n",
       " 'The response generated by a large language model is: 3',\n",
       " 'The response generated by a large language model (LLM) is: 3']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_outputs = evaluate_gpt(inputs, responses, ai_task)\n",
    "ai_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QiJME0JTb5d6"
   },
   "outputs": [],
   "source": [
    "def evaluateMetric(output, humanTarget):\n",
    "    count_match = 0\n",
    "    problematic_outputs_idx = []\n",
    "    for idx, (target, out) in enumerate(zip(humanTarget, output)):\n",
    "        if target in out:\n",
    "            count_match += 1\n",
    "        if target not in [\"1\", \"2\", \"3\"]:\n",
    "            problematic_outputs_idx.append(idx)\n",
    "\n",
    "    return count_match, problematic_outputs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aELFTIZzeZZL"
   },
   "outputs": [],
   "source": [
    "def listProblematicOutputs(problematic_outputs_idx, outputs, answers):\n",
    "  if len(problematic_outputs_idx) > 0:\n",
    "    mask = np.array(problematic_outputs_idx)\n",
    "    problematic_outputs = np.array(outputs)[mask]\n",
    "    problematic_answers = np.array(answers)[mask]\n",
    "\n",
    "    for idx, out, answer in zip(problematic_outputs_idx, problematic_outputs, problematic_answers):\n",
    "      print(idx, out, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ONzqFx_dc_y2"
   },
   "outputs": [],
   "source": [
    "n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hCXTcWDcd_A",
    "outputId": "b24a7468-fa07-45ac-a5bd-7d828f252304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count correct:  31\n",
      "count correct:  27\n",
      "count correct:  28\n",
      "count correct:  26\n",
      "count correct:  26\n",
      "count correct:  28\n",
      "count correct:  29\n",
      "count correct:  26\n",
      "count correct:  26\n",
      "count correct:  29\n",
      "count correct:  27\n",
      "count correct:  26\n",
      "count correct:  27\n",
      "count correct:  30\n",
      "count correct:  29\n",
      "count correct:  28\n",
      "count correct:  27\n",
      "count correct:  25\n",
      "count correct:  24\n",
      "count correct:  23\n",
      "542 27.1\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "for i in range(n):\n",
    "    funny_outputs = evaluate_gpt(inputs, responses, funny_task)\n",
    "    count_funny, problematic_funny_idx = evaluateMetric(funny_outputs, winningAnswerIdx)\n",
    "    print(\"count correct: \",count_funny)\n",
    "    total_count += count_funny\n",
    "    listProblematicOutputs(problematic_funny_idx, funny_outputs, winningAnswerIdx)\n",
    "print(total_count, total_count / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fI_Ss9A9KNFF",
    "outputId": "d0a27b32-60c9-4a6e-dd5b-a0ad287bcd49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count correct:  30\n",
      "count correct:  25\n",
      "count correct:  27\n",
      "count correct:  28\n",
      "count correct:  25\n",
      "count correct:  30\n",
      "count correct:  26\n",
      "count correct:  27\n",
      "count correct:  26\n",
      "count correct:  25\n",
      "count correct:  26\n",
      "count correct:  27\n",
      "count correct:  24\n",
      "count correct:  29\n",
      "count correct:  25\n",
      "count correct:  29\n",
      "count correct:  27\n",
      "count correct:  28\n",
      "count correct:  29\n",
      "count correct:  26\n",
      "539 26.95\n"
     ]
    }
   ],
   "source": [
    "total_ai_count = 0\n",
    "for i in range(n):\n",
    "    ai_outputs = evaluate_gpt(inputs, responses, ai_task)\n",
    "    count_aiSubmitters, problematic_ai_idx = evaluateMetric(ai_outputs, aiSubmitters)\n",
    "    print(\"count correct: \",count_aiSubmitters)\n",
    "    total_ai_count += count_aiSubmitters\n",
    "    listProblematicOutputs(problematic_ai_idx, ai_outputs, count_aiSubmitters)\n",
    "print(total_ai_count, total_ai_count / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8jHP8kxU-9q"
   },
   "source": [
    "https://lmarena.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjcE1NDyv2bH"
   },
   "source": [
    "# Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "17b29c35a719447baec9a788887da5b8",
      "6b50dcb44aa14a4aa65bd6cca3dd9e2d",
      "f08277a32dec4e84a5f1aa9e40acc210",
      "c8d29059d85c42ae9739397f95506765",
      "e025c29539174e46ba8c27d11c86fff5",
      "5352c4c5f13944ce9c2f302f54369fd4",
      "e86ffe03dfd9444f88b49220e8f35490",
      "0ae04d19e0bc4a499bab66c224419143",
      "8e10e44492e640ad874919e00f7b8c9a",
      "2a7211be38ea4bc2856d20934fe209f6",
      "07102641a0f4449eab883f3ebef56984",
      "d66233b64d4a45ed8fe3fb33794164ff",
      "94409933131e433a9591305203efeb4d",
      "a1362f306f8a4d08840c2b3d4faee0ef",
      "00a7d76ff99d41f99062e422d5f878d5",
      "21de95193ed740df9ac33a2c36fcc8d2",
      "a6f16c2296c2464baa3381ec91a2b65d",
      "7b71d66ab0d64d42b33392ddaf1e6c11",
      "d893683ab2f249579bb99c8ae1e8df8e",
      "961531e7727f4f99a0f8b55cb210c68b"
     ]
    },
    "id": "Fxa94eK0_vhA",
    "outputId": "8abaab1c-4822-4d6f-a1e9-39d8a9400088"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b29c35a719447baec9a788887da5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338,
     "referenced_widgets": [
      "81d2197091504f1189d93c08c1159fe8",
      "27ffeda482534892ba9cd09a94786010",
      "3bba454b992b4735a7f5c9487735fa39",
      "d8ae665afa38439e81a377ae61251ee0",
      "a358cdbb383849acaa551ccbadfdbddb",
      "b902f1aed03f45898d0f7849bf4e9e16",
      "1a127e9bb42d459bbf47fb6dc29e618d",
      "7a0b054d2af84e169d5c06a0abdbbd48",
      "209174c9d4f940c695121d19e5bf3336",
      "393d25144c3640fc85ffa67f99194432",
      "38e85470667044f090287ab8846c92ae",
      "23bf5a5a92b6458da670834246ea3c59",
      "d07323be9ee54deebc1e293329c63e6d",
      "bcde01eb4a6147c29ec0ee5cc82bbc37",
      "409f7e92d70746b89a3d73cd25bcd5a7",
      "bc9f105cdb304f228d2dae279ffc032a",
      "b9b74971021c4d5fa62bde2da8ba7db1",
      "db3d8a63a3d84b4d90911adf6a3295a9",
      "b44beb8e68434a04862f072768c1cb29",
      "f082479ee666425ea85b1b8be5a630d5",
      "33c43bbc048045d48422943cb18c195f",
      "4fea95f16d7143b09518133613519336",
      "0f250f8f74ff4d2791b1af99c48d3a54",
      "da9a1a92821b4ea38ada232da5fe70b0",
      "a2b8cbbbf46948c1aa989333a68740d5",
      "04754d2ef4ac484faa11eb430efc56ee",
      "a65a64600a98497fa16d8fefc6386f49",
      "0bddffd06567416eb968c8bfeb75c7d7",
      "5e415c7e54e04b09b719dfa9c0fb53ff",
      "a9919c62f82d4422ad74462a02b19ae0",
      "c80b0aca004146e7b30dec77299828c5",
      "2acc7ba4d02742d692fc73a2b7d35679",
      "2aadbd657e764ed6bb86102594c98740",
      "721d4292a12d47da85c257a5593f967f",
      "0d74ee157c56414da10abe906baff65c",
      "5c93916b0a684941a12020d25edf1283",
      "9e764366f0c044598fe3573156d6e707",
      "0bced9feff38404f8457b27154cca823",
      "cdac947d113a4177b4ba4d75443a6a12",
      "b01412b7612041919f84850444f38dcc",
      "b10d66e4ac154368aa149f0fec19070c",
      "59c530dfa6a34fa79baeb5e72812628f",
      "4e06bb21f32e489ea3e489ef89987f65",
      "fb70d75548e34a38a3056d4cb87154b7",
      "522ada74b32948d2822b0619f650c675",
      "2ab2001737724bbe97edf7e7516e0658",
      "2618f9fd9f94423aa98b45bba9063d87",
      "84dc31ba0d4d4040858508c131e4e156",
      "fe101f497b9f4d39954a0c5ae6f20532",
      "43fba18d10f448bbb8408e5a2156c512",
      "658f43b8842546fbadb23309e5d474dc",
      "3d35c7128ff14a4785f0fe258a34dae0",
      "ed9ef33e86884d42a34bfbac257df9bf",
      "25eb617c6e8c41e4b7ddaaafe02b4203",
      "cdecd42991cd4288a0528204ec4488b8",
      "2270c1616e494b54940c3631947dbf56",
      "4bc48fb06c8248ac849f48fa439e3773",
      "b61905ff47db47b5bcf3a3446344052e",
      "4defeffd54be42d8ac5d0448293095e8",
      "227e45d40a354db8b034f55cc74bd685",
      "3ffd7b90d6924b2f98e796dd3b5d9802",
      "dab1e67efd0340f18c1f3e5b63d0d9ea",
      "6bea828a489044e1ad8d32ca577c6042",
      "feb408d34b964241b7266986e90ae3b7",
      "0b99233a9d71423d913ecb9e81239ff6",
      "3d63cc33a4314c31b79afecaa09c388a"
     ]
    },
    "id": "DXfsDQzYTRwM",
    "outputId": "466ec37a-434a-47a0-ca4f-19189c1be771"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d2197091504f1189d93c08c1159fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bf5a5a92b6458da670834246ea3c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f250f8f74ff4d2791b1af99c48d3a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721d4292a12d47da85c257a5593f967f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522ada74b32948d2822b0619f650c675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2270c1616e494b54940c3631947dbf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# TODO: Load the model using the appropriate parameters using AutoModelForCausalLM\n",
    "# Ensure torch_dtype is set to torch.bfloat16\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# TODO: Initialize the tokenizer using AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntMhj1MkTZOt"
   },
   "outputs": [],
   "source": [
    "def run_model(model, tokenizer, messages, max_new_tokens=5, verbose=False):\n",
    "    # TODO: Prepare the input text using the tokenizer's apply_chat_template (Do not tokenize the text yet)\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    if verbose: print(\"\\n###input_text:###\\n\", input_text)\n",
    "    # TODO: Tokenize the input text and transfer it to the appropriate device\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "    if verbose: print(\"\\n###input_ids:###\\n\", input_ids)\n",
    "    # TODO: Generate a response using the model. Ensure do_sample is False.\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        temperature = 1.0,\n",
    "        top_p = 1.0,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # TODO: Decode the output and return the response without special tokens\n",
    "    # https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct#transformers-automodelforcausallm\n",
    "    response = tokenizer.decode(output[0][input_ids.shape[-1]:], skip_special_tokens=True)    # output[0][input_ids.shape[-1]:] REMOVES the inputs from response\n",
    "    assistant_response = response.split(\"assistant\")[1].strip() if \"assistant\" in response else response\n",
    "\n",
    "    if verbose: print(\"\\n###response:###\\n\", response)\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IuthrnLeu5B"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def run_llama(model, tokenizer, inputs, responses, task):\n",
    "\n",
    "    messages = generate_messages(task, inputs, responses)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for msg in messages:\n",
    "        output = run_model(model, tokenizer, msg, max_new_tokens=5, verbose=False).lower().strip()\n",
    "        outputs.append(output)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhMH_ES83bPg",
    "outputId": "c8379fdd-690f-448e-e026-35c74f0a2ec9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['response',\n",
       " 'response',\n",
       " 'response',\n",
       " 'based',\n",
       " 'response',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'response',\n",
       " 'after',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'response',\n",
       " 'based',\n",
       " 'response',\n",
       " 'after',\n",
       " 'i',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'response',\n",
       " 'based',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'response',\n",
       " 'response',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'after',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'response',\n",
       " 'based',\n",
       " 'after',\n",
       " 'based',\n",
       " 'response',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'after',\n",
       " 'based',\n",
       " 'response',\n",
       " 'response']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funny_outputs = run_llama(model, tokenizer, inputs, responses, funny_task)\n",
    "funny_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CoLSWfg7fa-",
    "outputId": "ff17d727-919b-4200-8a2c-0e6baebc3859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'the',\n",
       " 'based',\n",
       " 'response',\n",
       " 'based',\n",
       " 'the',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'response',\n",
       " 'based',\n",
       " 'i',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'the',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'the',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'response',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based',\n",
       " 'based']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_outputs = run_llama(model, tokenizer,  inputs, responses, ai_task)\n",
    "ai_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2L1oYB4din9"
   },
   "outputs": [],
   "source": [
    "total_count_llama = 0\n",
    "for i in range(n):\n",
    "    funnyllama_outputs = evaluate_gpt(inputs, responses, funny_task)\n",
    "    count_funny, problematic_funnyllama_idx = evaluateMetric(funnyllama_outputs, winningAnswerIdx)\n",
    "    print(\"count correct: \",count_funny)\n",
    "    total_count_llama += count_funny\n",
    "    listProblematicOutputs(problematic_funnyllama_idx, funnyllama_outputs, winningAnswerIdx)\n",
    "print(total_count_llama, total_count_llama / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW4AU6Zgdti_"
   },
   "outputs": [],
   "source": [
    "total_aicount_llama = 0\n",
    "for i in range(n):\n",
    "    ai_llama_outputs = evaluate_gpt(inputs, responses, ai_task)\n",
    "    count_aiSubmitters, problematic_ai_idx_llama = evaluateMetric(ai_llama_outputs, aiSubmitters)\n",
    "    print(\"count correct: \",count_aiSubmitters)\n",
    "    total_aicount_llama += count_aiSubmitters\n",
    "    listProblematicOutputs(problematic_ai_idx_llama, ai_llama_outputs, count_aiSubmitters)\n",
    "print(total_aicount_llama, total_aicount_llama / n)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "tEKD6dT6vyUF",
    "9qbpWkaxxwu-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00a7d76ff99d41f99062e422d5f878d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "04754d2ef4ac484faa11eb430efc56ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2acc7ba4d02742d692fc73a2b7d35679",
      "placeholder": "​",
      "style": "IPY_MODEL_2aadbd657e764ed6bb86102594c98740",
      "value": " 189/189 [00:00&lt;00:00, 8.30kB/s]"
     }
    },
    "07102641a0f4449eab883f3ebef56984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ae04d19e0bc4a499bab66c224419143": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b99233a9d71423d913ecb9e81239ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bced9feff38404f8457b27154cca823": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bddffd06567416eb968c8bfeb75c7d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d74ee157c56414da10abe906baff65c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdac947d113a4177b4ba4d75443a6a12",
      "placeholder": "​",
      "style": "IPY_MODEL_b01412b7612041919f84850444f38dcc",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "0f250f8f74ff4d2791b1af99c48d3a54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da9a1a92821b4ea38ada232da5fe70b0",
       "IPY_MODEL_a2b8cbbbf46948c1aa989333a68740d5",
       "IPY_MODEL_04754d2ef4ac484faa11eb430efc56ee"
      ],
      "layout": "IPY_MODEL_a65a64600a98497fa16d8fefc6386f49"
     }
    },
    "17b29c35a719447baec9a788887da5b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_e86ffe03dfd9444f88b49220e8f35490"
     }
    },
    "1a127e9bb42d459bbf47fb6dc29e618d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "209174c9d4f940c695121d19e5bf3336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21de95193ed740df9ac33a2c36fcc8d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2270c1616e494b54940c3631947dbf56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bc48fb06c8248ac849f48fa439e3773",
       "IPY_MODEL_b61905ff47db47b5bcf3a3446344052e",
       "IPY_MODEL_4defeffd54be42d8ac5d0448293095e8"
      ],
      "layout": "IPY_MODEL_227e45d40a354db8b034f55cc74bd685"
     }
    },
    "227e45d40a354db8b034f55cc74bd685": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23bf5a5a92b6458da670834246ea3c59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d07323be9ee54deebc1e293329c63e6d",
       "IPY_MODEL_bcde01eb4a6147c29ec0ee5cc82bbc37",
       "IPY_MODEL_409f7e92d70746b89a3d73cd25bcd5a7"
      ],
      "layout": "IPY_MODEL_bc9f105cdb304f228d2dae279ffc032a"
     }
    },
    "25eb617c6e8c41e4b7ddaaafe02b4203": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2618f9fd9f94423aa98b45bba9063d87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d35c7128ff14a4785f0fe258a34dae0",
      "max": 9085657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed9ef33e86884d42a34bfbac257df9bf",
      "value": 9085657
     }
    },
    "27ffeda482534892ba9cd09a94786010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b902f1aed03f45898d0f7849bf4e9e16",
      "placeholder": "​",
      "style": "IPY_MODEL_1a127e9bb42d459bbf47fb6dc29e618d",
      "value": "config.json: 100%"
     }
    },
    "2a7211be38ea4bc2856d20934fe209f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aadbd657e764ed6bb86102594c98740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ab2001737724bbe97edf7e7516e0658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43fba18d10f448bbb8408e5a2156c512",
      "placeholder": "​",
      "style": "IPY_MODEL_658f43b8842546fbadb23309e5d474dc",
      "value": "tokenizer.json: 100%"
     }
    },
    "2acc7ba4d02742d692fc73a2b7d35679": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33c43bbc048045d48422943cb18c195f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38e85470667044f090287ab8846c92ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "393d25144c3640fc85ffa67f99194432": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bba454b992b4735a7f5c9487735fa39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a0b054d2af84e169d5c06a0abdbbd48",
      "max": 877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_209174c9d4f940c695121d19e5bf3336",
      "value": 877
     }
    },
    "3d35c7128ff14a4785f0fe258a34dae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d63cc33a4314c31b79afecaa09c388a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ffd7b90d6924b2f98e796dd3b5d9802": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "409f7e92d70746b89a3d73cd25bcd5a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33c43bbc048045d48422943cb18c195f",
      "placeholder": "​",
      "style": "IPY_MODEL_4fea95f16d7143b09518133613519336",
      "value": " 2.47G/2.47G [00:59&lt;00:00, 42.4MB/s]"
     }
    },
    "43fba18d10f448bbb8408e5a2156c512": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bc48fb06c8248ac849f48fa439e3773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ffd7b90d6924b2f98e796dd3b5d9802",
      "placeholder": "​",
      "style": "IPY_MODEL_dab1e67efd0340f18c1f3e5b63d0d9ea",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "4defeffd54be42d8ac5d0448293095e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b99233a9d71423d913ecb9e81239ff6",
      "placeholder": "​",
      "style": "IPY_MODEL_3d63cc33a4314c31b79afecaa09c388a",
      "value": " 296/296 [00:00&lt;00:00, 17.5kB/s]"
     }
    },
    "4e06bb21f32e489ea3e489ef89987f65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fea95f16d7143b09518133613519336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "522ada74b32948d2822b0619f650c675": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ab2001737724bbe97edf7e7516e0658",
       "IPY_MODEL_2618f9fd9f94423aa98b45bba9063d87",
       "IPY_MODEL_84dc31ba0d4d4040858508c131e4e156"
      ],
      "layout": "IPY_MODEL_fe101f497b9f4d39954a0c5ae6f20532"
     }
    },
    "5352c4c5f13944ce9c2f302f54369fd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21de95193ed740df9ac33a2c36fcc8d2",
      "placeholder": "​",
      "style": "IPY_MODEL_a6f16c2296c2464baa3381ec91a2b65d",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "59c530dfa6a34fa79baeb5e72812628f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c93916b0a684941a12020d25edf1283": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b10d66e4ac154368aa149f0fec19070c",
      "max": 54528,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59c530dfa6a34fa79baeb5e72812628f",
      "value": 54528
     }
    },
    "5e415c7e54e04b09b719dfa9c0fb53ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "658f43b8842546fbadb23309e5d474dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b50dcb44aa14a4aa65bd6cca3dd9e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ae04d19e0bc4a499bab66c224419143",
      "placeholder": "​",
      "style": "IPY_MODEL_8e10e44492e640ad874919e00f7b8c9a",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "6bea828a489044e1ad8d32ca577c6042": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "721d4292a12d47da85c257a5593f967f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d74ee157c56414da10abe906baff65c",
       "IPY_MODEL_5c93916b0a684941a12020d25edf1283",
       "IPY_MODEL_9e764366f0c044598fe3573156d6e707"
      ],
      "layout": "IPY_MODEL_0bced9feff38404f8457b27154cca823"
     }
    },
    "7a0b054d2af84e169d5c06a0abdbbd48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b71d66ab0d64d42b33392ddaf1e6c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d893683ab2f249579bb99c8ae1e8df8e",
      "placeholder": "​",
      "style": "IPY_MODEL_961531e7727f4f99a0f8b55cb210c68b",
      "value": "Connecting..."
     }
    },
    "81d2197091504f1189d93c08c1159fe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27ffeda482534892ba9cd09a94786010",
       "IPY_MODEL_3bba454b992b4735a7f5c9487735fa39",
       "IPY_MODEL_d8ae665afa38439e81a377ae61251ee0"
      ],
      "layout": "IPY_MODEL_a358cdbb383849acaa551ccbadfdbddb"
     }
    },
    "84dc31ba0d4d4040858508c131e4e156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25eb617c6e8c41e4b7ddaaafe02b4203",
      "placeholder": "​",
      "style": "IPY_MODEL_cdecd42991cd4288a0528204ec4488b8",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 22.5MB/s]"
     }
    },
    "8e10e44492e640ad874919e00f7b8c9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94409933131e433a9591305203efeb4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "961531e7727f4f99a0f8b55cb210c68b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e764366f0c044598fe3573156d6e707": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e06bb21f32e489ea3e489ef89987f65",
      "placeholder": "​",
      "style": "IPY_MODEL_fb70d75548e34a38a3056d4cb87154b7",
      "value": " 54.5k/54.5k [00:00&lt;00:00, 3.09MB/s]"
     }
    },
    "a1362f306f8a4d08840c2b3d4faee0ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2b8cbbbf46948c1aa989333a68740d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9919c62f82d4422ad74462a02b19ae0",
      "max": 189,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c80b0aca004146e7b30dec77299828c5",
      "value": 189
     }
    },
    "a358cdbb383849acaa551ccbadfdbddb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a65a64600a98497fa16d8fefc6386f49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6f16c2296c2464baa3381ec91a2b65d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9919c62f82d4422ad74462a02b19ae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b01412b7612041919f84850444f38dcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b10d66e4ac154368aa149f0fec19070c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44beb8e68434a04862f072768c1cb29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b61905ff47db47b5bcf3a3446344052e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bea828a489044e1ad8d32ca577c6042",
      "max": 296,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_feb408d34b964241b7266986e90ae3b7",
      "value": 296
     }
    },
    "b902f1aed03f45898d0f7849bf4e9e16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9b74971021c4d5fa62bde2da8ba7db1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc9f105cdb304f228d2dae279ffc032a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcde01eb4a6147c29ec0ee5cc82bbc37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b44beb8e68434a04862f072768c1cb29",
      "max": 2471645608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f082479ee666425ea85b1b8be5a630d5",
      "value": 2471645608
     }
    },
    "c80b0aca004146e7b30dec77299828c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c8d29059d85c42ae9739397f95506765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_d66233b64d4a45ed8fe3fb33794164ff",
      "style": "IPY_MODEL_94409933131e433a9591305203efeb4d",
      "value": true
     }
    },
    "cdac947d113a4177b4ba4d75443a6a12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdecd42991cd4288a0528204ec4488b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d07323be9ee54deebc1e293329c63e6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9b74971021c4d5fa62bde2da8ba7db1",
      "placeholder": "​",
      "style": "IPY_MODEL_db3d8a63a3d84b4d90911adf6a3295a9",
      "value": "model.safetensors: 100%"
     }
    },
    "d66233b64d4a45ed8fe3fb33794164ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d893683ab2f249579bb99c8ae1e8df8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8ae665afa38439e81a377ae61251ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_393d25144c3640fc85ffa67f99194432",
      "placeholder": "​",
      "style": "IPY_MODEL_38e85470667044f090287ab8846c92ae",
      "value": " 877/877 [00:00&lt;00:00, 62.6kB/s]"
     }
    },
    "da9a1a92821b4ea38ada232da5fe70b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bddffd06567416eb968c8bfeb75c7d7",
      "placeholder": "​",
      "style": "IPY_MODEL_5e415c7e54e04b09b719dfa9c0fb53ff",
      "value": "generation_config.json: 100%"
     }
    },
    "dab1e67efd0340f18c1f3e5b63d0d9ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db3d8a63a3d84b4d90911adf6a3295a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e025c29539174e46ba8c27d11c86fff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_a1362f306f8a4d08840c2b3d4faee0ef",
      "style": "IPY_MODEL_00a7d76ff99d41f99062e422d5f878d5",
      "tooltip": ""
     }
    },
    "e86ffe03dfd9444f88b49220e8f35490": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "ed9ef33e86884d42a34bfbac257df9bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f082479ee666425ea85b1b8be5a630d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f08277a32dec4e84a5f1aa9e40acc210": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_2a7211be38ea4bc2856d20934fe209f6",
      "placeholder": "​",
      "style": "IPY_MODEL_07102641a0f4449eab883f3ebef56984",
      "value": ""
     }
    },
    "fb70d75548e34a38a3056d4cb87154b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe101f497b9f4d39954a0c5ae6f20532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feb408d34b964241b7266986e90ae3b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
